http://stackoverflow.com/questions/1893072/getting-frames-from-video-image-in-android

http://developer.android.com/reference/android/hardware/camera2/package-summary.html

http://code.google.com/p/globetrotter/source/browse/trunk/src/com/ece194/globetrotter/CameraActivity.java



public override bool FinishedLaunching (UIApplication app, NSDictionary options)
{
  ImageView = new UIImageView (new CGRect (20, 20, 280, 280));
  ImageView.ContentMode = UIViewContentMode.ScaleAspectFill;

  vc = new UIViewController ();
  vc.View = ImageView;
  window.RootViewController = vc;

  window.MakeKeyAndVisible ();
  window.BackgroundColor = UIColor.Black;

  if (!SetupCaptureSession ())
    window.AddSubview (new UILabel (new CGRect (20, 20, 200, 60)) { Text = "No input device" });

  return true;
}


https://developer.apple.com/library/ios/qa/qa1702/_index.html

http://www.ios-developer.net/iphone-ipad-programmer/development/camera/record-video-with-avcapturesession-2

https://developer.apple.com/library/ios/samplecode/GLCameraRipple/Introduction/Intro.html

http://stackoverflow.com/questions/24024764/errors-showing-for-oes-opengl-statements-in-xcode-6-for-ios8

http://stackoverflow.com/questions/12821364/cant-use-dispatch-sync-in-c-class-with-objective-c-code


http://stackoverflow.com/questions/5559652/how-do-i-detect-the-orientation-of-the-device-on-ios

Add to .mm

@implementation Wrapper
- (void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection {
    // doing copying to currentBuffer
    NSLog(@"Capture2");
}
@end


Add to .h

#ifdef __OBJC__

#import <Foundation/Foundation.h>
#import <AVFoundation/AVFoundation.h>

@interface Wrapper : NSObject <AVCaptureVideoDataOutputSampleBufferDelegate> {
    CMSampleBufferRef currentBuffer;
}
@end

#endif
